{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paradigma del machine learning vs programmazione tradizionale\n",
    "Nel caso della programmazione tradizionale, è il programmatore a definire esplicitamente le regole da seguire. \n",
    "Per quanto concerne il machine learning (che ricordiamo essere sotto-categoria dell'intelligenza artificiale), la macchina comprende e prevede automaticamente le regole da seguire, in seguito a una fase di addestramento. Chiaramente, risulta essere una pratica più dispensiosa, ma adatta a problemi complessi, che la programmazione tradizionale non è in grado di risolvere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparazione dei dati\n",
    "Prima di procedere con la fase di training di una rete, una volta che i dati sono stati acquisiti, è necessario procedere con la fase di annotazione, cioè la fase in cui si attribuisce un'etichetta a un dato: essa indica il contenuto effettivo del dato. Nel caso in cui l'addestramento di una rete avvenga senza dati etichettati, si parla di training supervisionato. In questo caso, è la rete che deve apprendere il tipo di dato che sta gestendo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task del machine learning\n",
    "I task del machine learning sono 3: \n",
    "1. Classificazione: si tratta del compito di comprendere, a partire da un dato, la categoria, appunto la classe, a cui appartiene. La classificazione può essere binaria, se riguarda 2 classi, oppure multiclasse.\n",
    "2. Regressione: si tratta del compito di ottenere una funzione a partire da dati. Ad esempio, se la rete è stata allenata su altezza e peso di un campione di persone, allora, a partire da un'altezza, si deve prevedere il peso stimato di tale persona.\n",
    "3. Clustering (possibile anche per dati non etichettati): dato l'input, si vogliono raggruppare dati insieme quando possibile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessità di una fase di feaature extraction nel machine learning\n",
    "La fase di feature extraction nel machine learning implica l'estrazione di caratteristiche rilevanti dai dati grezzi che saranno utilizzate per addestrare un modello. \n",
    "Riduce il numero di variabili sotto considerazione, semplificando il modello e migliorando le sue prestazioni, permettendo di concentrarsi sulle caratteristiche più informative, eliminando il rumore dai dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training di una rete neurale. Forward Propagagation e Backward Propagation\n",
    "Per training di una rete neurale si intende il ripetere la previsione da parte della rete di dati prestabiliti. \n",
    "Per forward propagation, si intende il far scorrere tutti i dati (training set) attraverso la rete, calcolando per ogni neurone la soglia di attivazione. \n",
    "Per backward propagation, si intende il calcolo del gradiente della funzione di loss con l'obiettivo di minimizzarla, quindi migliorando i pesi. Tale operazione viene svolta sfruttando la chain rule del calcolo differenziale per calcolare la derivata di funzioni composte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function e Funzione costo.\n",
    "La loss function misura la distanza dall'output desiderato per ogni neurone di ogni strato della rete neurale. \n",
    "La funzione di costo misura la distanza dall'output dell'intero dataset della rete; quindi, è come se la funzione costo tenesse in considerazione tutte le funzioni di perdita dei neuroni della rete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reti neurali Convoluzionali: limiti delle reti MLP nell’elaborazione delle immagini. Mancanza di  invarianza per traslazione.\n",
    "Le reti convoluzionali (CNN) sono reti neurali in grado di risolvere operazioni più complesse rispetto ai MLP nell'azione di riconoscimento. Infatti, le CNN principalmente vengono utilizzate per processare immagini. \n",
    "Il concetto fondante è quello di struttura tridimensionale: lunghezza, larghezza, profondità variabile. Si definisce kernel o filtro la dimensione di una rete CNN, che è 3x3x1.\n",
    "Le immagini vengono processate attraverso la fase di convoluzione, un meccanismo a scorrimentno, che prevede appunto lo scorrimento del filtro/kernel su ogni pixel dell'immagine. Per ogni posizione, si calcola il prodotto scalare tra la maschera e la porzione di input coperta. \n",
    "L'output è detto feature-map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tecniche di Ottimizzazione: metodo di discesa del gradient batch, metodo del gradiente stocastico (SGD), metodo del gradiente stocastico minibatch. \n",
    "1. Metodo di discesa del gradiente batch: la funzione di loss viene calcolata attraverso una fase di forward propagation, per poi iaggiornare i pesi attraverso una fase di backward propagation. In questo modo, i dati vengono aggiornati una singola volta. \n",
    "2. Metodo di discesa del gradiente stocastico: si tratta di un algoritmo per minimizzare la funzione di loss, il quale prevede il miglioramento dei pesi ad ogni iterazione attraverso backward propagation.\n",
    "3. Metodo del gradiente minibatch: si considera un sottoinsieme del data-set. Se l'intera rete neurale ha N osservazioni, allora il mini-batch conterrà 1 < x < n osservazioni. Ogni osservazione indica il numero di campioni da far scorrere all'interno della rete ad ogni iterazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sotto quali condizioni, il metodo di discesa del gradiente con passo fisso converge a un punto stazionario della funzione costo, che può essere un minimo globale se la funzione è convessa? Non convessità della funzione di costo.\n",
    "Il metodo di discesa del gradiente con passo fisso converge a un punto stazionario della funzione costo se e sole se la funzione costo è continua e differenziabile, con gradiente L.\n",
    "Se la funzione è convessa, si ha la certezza che il punto di minimo locale trovato con il metodo del gradiente è un punto di minimo globale. In particolare, una funzione di loss è sicuramente convessa se non ha hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo di ottimizzazione del gradient descent con momento. Perchè è stato studiato e formula di aggiornamento dei pesi.\n",
    "Il metodo di discesa del gradiente con momento è stato studiato per accelerare la convergenza e migliorare le oscillazioni. \n",
    "Ricordiamo che i pesi vengono aggiornati secondo la seguente relazione: w(k+1) = w(k) + n*v, n = learning rate, v = Beta * v(k-1) + Gradiente(C). \n",
    "V è la velocità accumulata dal passo precedente, e serve per comprendere se aggiornare ampliamente i pesi se i gradienti puntano alla stessa direzione, oppure se diminuire i pesi se i gradienti puntano in direzioni diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate scheduling: step decay, decadimento esponenziale, decadimento dipendente dal tempo.\n",
    "Ricordiamo cos'è il learning rate: si tratta di un iperparametro della rete (dunque appartiene all'insieme di validation set, e non training set). Se si ha un valore troppo alto di learning rate, allora è probabile non convergere alla soluzione cercata, mentre valori troppo bassi fanno sì che si converga alla soluzione in un numero di iterazioni decisamente elevato. Sarebbe necessario un learning rate dinamico, il quale ha valore medio-alto nella fase iniziale di ricerca, e valore basso nella fase finale. \n",
    "1. step decay: per ogni iterazione, il learning rate viene diminuito di un certo fattore delta.\n",
    "2. decadimento esponenziale: il learning rate diminuisce esponenzialmente in base al numero di iterazioni svolte: n = n * e**(-k*t) \n",
    "3. decadimento dipendente dal tempo: il learning rate iniziale viene diviso per il numero di iterazioni svolte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate adattivo: Adagrad, RMSProp, Adadelta, Adam.\n",
    "1. Adagrad: adatta il learning rate, aggiornando ampiamente dati con bassa frequenza e viceversa. Aspetto negativo = accumulto dei gradienti quadrati => può portare a un learning rate estremamente basso, con una scarsa efficienza.\n",
    "2. RMSProp: migliora Adagrad, sostituendo l'accumulo dei gradienti quadrati con la media ponderata esponenziale dei gardienti quadrati.\n",
    "3. Adadelta: aggiorna i pesi come RMSProp, tuttavia non necessita di stabilire il learning rate iniziale. La rete comprende la quantità di cambiamento e la usa per calibrare i cambiamenti successivi.\n",
    "4. Adam: utilizza il metodo di discesa del gradiente con momentum e RMSProp. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
